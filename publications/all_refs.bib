@Book{MeridaCasermeiro2008,
  author = {E. M{\a'e}rida-Casermeiro and D. L{\a'o}pez-Rodr{\a'\i}guez and J.M. Ortiz-de-Lazcano-Lobato},
  publisher = {IGI Global},
  title = {An approach to artificial concept learning based on human concept learning by using artificial neural networks},
  year = {2008},
  abstract = {In this chapter, two important issues concerning associative memory by neural networks are studied: a new model of hebbian learning, as well as the effect of the network capacity when retrieving patterns and performing clustering tasks. Particularly, an explanation of the energy function when the capacity is exceeded: the limitation in pattern storage implies that similar patterns are going to be identified by the network, therefore forming different clusters. This ability can be translated as an unsupervised learning of pattern clusters, with one major advantage over most clustering algorithms: the number of data classes is automatically learned, as confirmed by the experiments. Two methods to reinforce learning are proposed to improve the quality of the clustering, by enhancing the learning of patterns relationships. As a related issue, a study on the net capacity, depending on the number of neurons and possible outputs, is presented, and some interesting conclusions are commented. © 2009, IGI Global.},
  document_type = {Book Chapter},
  doi = {10.4018/978-1-59904-996-0.ch008},
  journal = {Advancing Artificial Intelligence Through Biological Process Applications},
  pages = {130-145},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84899353027&doi=10.4018%2f978-1-59904-996-0.ch008&partnerID=40&md5=9628e1467301f479b3293dc932c844b0},
}

@InCollection{CasermeiroLO09,
  author = {Enrique M{\a'e}rida Casermeiro and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Juan Miguel Ortiz-de-Lazcano-Lobato},
  editor = {Juan R. Rabu{\~n}al and Julian Dorado and Alejandro Pazos},
  title = {MREM, Discrete Recurrent Network for Optimization},
  booktitle = {Encyclopedia of Artificial Intelligence {(3} Volumes)},
  pages = {1112--1120},
  publisher = {{IGI} Global},
  year = {2009},
  url = {http://www.igi-global.com/Bookstore/Chapter.aspx?TitleId=10380},
}

@InBook{López-Rodríguez2022,
  author = {Domingo L{\a'o}pez-Rodr{\a'\i}guez and Emilio Mu{\~n}oz-Velasco and Manuel Ojeda-Aciego},
  editor = {Rokia Missaoui and L{\a'e}onard Kwuida and Talel Abdessalem},
  title = {Formal Methods in FCA and Big Data},
  booktitle = {Complex Data Analytics with Formal Concept Analysis},
  year = {2022},
  publisher = {Springer International Publishing},
  address = {Cham},
  pages = {201--224},
  abstract = {Formal Concept Analysis (FCA) plays an important role in knowledge representation and knowledge discovery, and has generated an increasingly growing research field. The use of FCA in the context of big data provides a basis for better interpretability and explainability of results, usually lacking in other statistical approaches to data analysis; however, scalability is an important issue for FCA logic-based tools and techniques, such as the generation and use of implicational systems. We survey the theoretical and technical foundations of some trends in FCA. Specifically, we present a summary of promising theoretical and practical applications of FCA that could be used to solve the problem of dealing with big data. Furthermore, we propose some directions for future research to solve this problem.},
  isbn = {978-3-030-93278-7},
  doi = {10.1007/978-3-030-93278-7_9},
  url = {https://doi.org/10.1007/978-3-030-93278-7_9},
}

@InCollection{dominguezsuper,
  title = {Super-Resolution of 3D Magnetic Resonance Images of the Brain},
  author = {Enrique Dom{\a'\i}nguez and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Ezequiel L{\a'o}pez-Rubio and Rosa Maza-Quiroga and Miguel A Molina-Cabello and Karl Thurnhofer-Hemsi},
  booktitle = {Artificial Intelligence in Healthcare and Medicine},
  pages = {157--176},
  year = {2022},
  publisher = {CRC Press},
}

@Proceedings{icfca2023,
  editor = {Dominik D{\"u}rrschnabel and Domingo L{\a'o}pez-Rodr{\a'\i}guez},
  title = {Formal Concept Analysis - 17th International Conference, {ICFCA} 2023,
                  Kassel, Germany, July 17-21, 2023, Proceedings},
  series = {Lecture Notes in Computer Science},
  volume = {13934},
  publisher = {Springer},
  year = {2023},
  doi = {10.1007/978-3-031-35949-1},
  isbn = {978-3-031-35948-4},
}

@InProceedings{lopez2019matrix,
  title = {Matrix bandwidth minimization: A neural approach},
  author = {D L{\a'o}pez-Rodr{\a'\i}guez and E M{\a'e}rida-Casermeiro},
  booktitle = {International Conference of Computational Methods in Sciences and Engineering 2004 (ICCMSE 2004)},
  pages = {324--327},
  year = {2019},
  organization = {CRC Press},
}

@InProceedings{merida2019multivalued,
  title = {Multivalued neural network for graph maxcut problem},
  author = {E M{\a'e}rida-Casermeiro and D L{\a'o}pez-Rodr{\a'\i}guez},
  booktitle = {International Conference of Computational Methods in Sciences and Engineering 2004 (ICCMSE 2004)},
  pages = {375--378},
  year = {2019},
  organization = {CRC Press},
}

@InProceedings{merida2005iterative,
  title = {Iterative Learning Reinforcement for Unsupervised Clustering with Discrete Recurrent Networks},
  author = {E. M{\a'e}rida-Casermeiro and D. L{\a'o}pez-Rodr{\a'\i}guez},
  booktitle = {XI Conferencia de la Asociación Española para la Inteligencia Artificial 2005},
  pages = {61--70},
  year = {2005},
  organization = {AEPIA},
}

@InProceedings{lopez2005neural,
  title = {Neural Formulation of Functional Annealing and Application to Traveling Salesman Problem},
  author = {Domingo L{\a'o}pez-Rodr{\a'\i}guez and Enrique M{\a'e}rida-Casermeiro},
  booktitle = {XI Conferencia de la Asociación Española para la Inteligencia Artificial 2005},
  pages = {71--80},
  year = {2005},
  organization = {AEPIA},
}

@InProceedings{LopezRodriguez2005,
  author = {Domingo L{\a'o}pez-Rodr{\a'\i}guez and Enrique M{\a'e}rida Casermeiro and Juan Miguel Ortiz-de-Lazcano-Lobato},
  booktitle = {International Enformatika Conference, IEC'05, August 26-28, 2005, Prague, Czech Republic, {CDROM}},
  title = {Hopfield Network as Associative Memory with Multiple Reference Points},
  year = {2005},
  editor = {Cemal Ardil},
  pages = {62--67},
  publisher = {Enformatika, {\c{C}}anakkale, Turkey},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/wec/Lopez-RodriguezCO05.bib},
  timestamp = {Thu, 13 Oct 2005 14:06:21 +0200},
}

@InProceedings{Casermeiro2005a,
  author = {Enrique M{\a'e}rida Casermeiro and Domingo L{\a'o}pez-Rodr{\a'\i}guez},
  booktitle = {Computational Intelligence and Bioinspired Systems, 8th International Work-Conference on Artificial Neural Networks, {IWANN} 2005, Vilanova i la Geltrú, Barcelona, Spain, June 8-10, 2005, Proceedings},
  title = {Graph Partitioning via Recurrent Multivalued Neural Networks},
  year = {2005},
  address = {Vilanova i la Geltru},
  editor = {Joan Cabestany and Alberto Prieto and Francisco Sandoval Hern{\a'a}ndez},
  pages = {1149--1156},
  publisher = {Springer},
  series = {Lecture Notes in Computer Science},
  volume = {3512},
  abstract = {In this work, the well-known Graph Partitioning (GP) problem for undirected weighted graphs has been studied from two points of view: maximizing (MaxCut) or minimizing (MinCut) the cost of the cut induced in the graph by the partition. An unified model, based on a neural technique for optimization problems, has been applied to these two concrete problems. A detailed description of the model is presented, and the technique to minimize an energy function, that measures the goodness of solutions, is fully described. Some techniques to escape from local optima are presented as well. It has proved to be a very competitive and efficient algorithm, in terms of quality of solutions and computational time, when compared to the state-of-the-art methods. Some simulation results are presented in this paper, to show the comparative efficiency of the methods. © Springer-Verlag Berlin Heidelberg 2005.},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/iwann/CasermeiroL05.bib},
  document_type = {Conference Paper},
  doi = {10.1007/11494669_141},
  journal = {Lecture Notes in Computer Science},
  keywords = {Algorithms; Computational methods; Computer simulation; Graph theory; Optimization; Problem solving, Computational time; Graph partitioning; Optimization problems, Neural networks},
  source = {Scopus},
  timestamp = {Tue, 14 May 2019 10:00:51 +0200},
  url = {https://doi.org/10.1007/11494669\_141},
}

@InProceedings{lopez2005aplicacion,
  title = {Aplicación neuronal del enfriamiento funcional discreto al problema del viajante},
  author = {Domingo L{\a'o}pez-Rodr{\a'\i}guez and Enrique M{\a'e}rida-Casermeiro},
  booktitle = {IV Congreso Español sobre Meraheurísticas, Algoritmos Evolutivos y Bioinspirados},
  pages = {307--314},
  year = {2005},
  organization = {CEDI},
}

@InProceedings{lopez2005memoria,
  title = {Memoria auto-asociativa y clasificación con redes neuronales recurrentes},
  author = {Enrique M{\a'e}rida-Casermeiro and Domingo L{\a'o}pez-Rodr{\a'\i}guez},
  booktitle = {IV Congreso Español sobre Meraheurísticas, Algoritmos Evolutivos y Bioinspirados},
  pages = {339--346},
  year = {2005},
  organization = {CEDI},
}

@InProceedings{Casermeiro2005,
  author = {E. M{\a'e}rida-Casermeiro and D. L{\a'o}pez-Rodr{\a'\i}guez},
  booktitle = {Current Topics in Artificial Intelligence, 11th Conference of the Spanish Association for Artificial Intelligence, {CAEPIA} 2005, Santiago de Compostela, Spain, November 16-18, 2005, Revised Selected Papers},
  title = {Hebbian Iterative Method for Unsupervised Clustering with Automatic Detection of the Number of Clusters with Discrete Recurrent Networks},
  year = {2005},
  address = {Santiago de Compostela},
  editor = {Roque Mar{\a'\i}n and Eva Onaindia and Alberto Bugar{\a'\i}n and Jos{\a'e} Santos Reyes},
  note = {cited By 3; Conference of 11th Conference of the Spanish Association for Artificial Intelligence, CAEPIA 2005 ; Conference Date: 16 November 2005 Through 18 November 2005; Conference Code:68379},
  pages = {241--250},
  publisher = {Springer},
  series = {Lecture Notes in Computer Science},
  volume = {4177},
  abstract = {In this paper, two important issues concerning pattern recognition by neural networks are studied: a new model of hebbian learning, as well as the effect of the network capacity when retrieving patterns and performing clustering tasks. Particularly, an explanation of the energy function when the capacity is exceeded: the limitation in pattern storage implies that similar patterns are going to be identified by the network, therefore forming different clusters. This ability can be translated as an unsupervised learning of pattern clusters, with one major advantage over most clustering algorithms: the number of data classes is automatically learned, as confirmed by the experiments. Two methods to reinforce learning are proposed to improve the quality of the clustering, by enhancing the learning of patterns relationships. As a related issue, a study on the net capacity, depending on the number of neurons and possible outputs, is presented, and some interesting conclusions are commented. © Springer-Verlag Berlin Heidelberg 2006.},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/caepia/CasermeiroL05.bib},
  document_type = {Conference Paper},
  doi = {10.1007/11881216\_26},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {Database systems; Iterative methods; Learning systems; Neural networks, Discrete recurrent networks; Hebbian iterative method; Retrieving patterns, Pattern recognition},
  source = {Scopus},
  sponsors = {CICYT - Minist. de Educ. y Ciencia; Direccion Xeral I+D Xunta de Galicia; Direccion Xeral Universidades Xunta de Galicia; Universidade de Santiago de Compostella; Universidade e Coruna},
  timestamp = {Tue, 14 May 2019 10:00:50 +0200},
  url = {https://doi.org/10.1007/11881216\_26},
}

@InProceedings{LopezRubio2006,
  author = {E. L{\a'o}pez-Rubio and J.M. Ortiz-de-Lazcano-Lobato and D. L{\a'o}pez-Rodr{\a'\i}guez and E. M{\a'e}rida-Casermeiro and M.D.C. Vargas-Gonz{\a'a}lez},
  booktitle = {Artificial Intelligence and Soft Computing, August 28-30, 2006, Palma de Mallorca, Spain},
  title = {Global-local learning strategies in probabilistic principal components analysis},
  year = {2006},
  address = {Palma de Mallorca},
  editor = {Angel P. {del Pobil}},
  note = {cited By 0; Conference of 10th IASTED International Conference on Artificial Intelligence and Soft Computing, ASC 2006 ; Conference Date: 28 August 2006 Through 30 August 2006; Conference Code:74030},
  pages = {46-51},
  publisher = {{IASTED/ACTA} Press},
  abstract = {We present a neural model which extends classical competitive learning by performing a Probabilistic Principal Components Analysis at each neuron. In the learning process is utilized a competition rule which try to get the better representation of the dataset while maintaining the homogeneity of the formed clusters. The model also has the ability to learn the number of basis vectors required to represent the principal directions of each cluster, so it overcomes a drawback of most local PCA models, where the dimensionality of a cluster must be fixed a priori.},
  author_keywords = {Competitive learning; Local PCA; Neural networks},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/asc/Lopez-RubioOLCV06.bib},
  document_type = {Conference Paper},
  journal = {Proceedings of the 10th IASTED International Conference on Artificial Intelligence and Soft Computing, ASC 2006},
  keywords = {Artificial intelligence; Education; Neural networks; Probability; Soft computing, Basis vectors; Competition rules; Competitive learning; Competitive learnings; Learning processes; Local learning strategies; Local PCA; Neural models; Pca models; Principal components analyses; Principal directions, Principal component analysis},
  source = {Scopus},
  sponsors = {Int. Assoc. Science and Technology for Development (IASTED); Technical Committee on Artificial Intelligence and Expert Systems; Technical Committee on Soft Computing},
  timestamp = {Thu, 18 Jul 2019 17:02:44 +0200},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-56149099517&partnerID=40&md5=d435d7f751c9133a83357d3c5c884fd0},
}

@InProceedings{Casermeiro2006,
  author = {Enrique M{\a'e}rida Casermeiro and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Juan Miguel Ortiz-de-Lazcano-Lobato},
  booktitle = {{ESANN} 2006, 14th European Symposium on Artificial Neural Networks, Bruges, Belgium, April 26-28, 2006, Proceedings},
  title = {Enhanced maxcut clustering with multivalued neural networks and functional annealing},
  year = {2006},
  pages = {25--30},
  publisher = {d-side publication},
  abstract = {In this work a new algorithm to improve the performance of optimization methods, by means of avoiding certain local optima, is described. Its theoretical bases are presented in a rigorous, but intuitive, way. It has been applied concretely to the case of recurrent neural networks, in particular to MREM, a multivalued recurrent model, that has proved to obtain very good results when dealing with NP-complete combinatorial optimization problems. In order to show its efficiency, the well-known MaxCut problem for graphs has been selected as benchmark. Our proposal outperforms other specialized and powerful techniques, as shown by simulations. © 2006 i6doc.com publication. All rights reserved.},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/esann/CasermeiroLO06.bib},
  document_type = {Conference Paper},
  journal = {ESANN 2006 Proceedings - European Symposium on Artificial Neural Networks},
  keywords = {Combinatorial optimization; Optimization, Combinatorial optimization problems; Its efficiencies; Local optima; MAX-CUT problem; Multi-valued; NP Complete; Optimization method; Recurrent models, Recurrent neural networks},
  source = {Scopus},
  timestamp = {Thu, 12 Mar 2020 11:36:02 +0100},
  url = {https://www.elen.ucl.ac.be/Proceedings/esann/esannpdf/es2006-86.pdf},
}

@InProceedings{LopezRodriguez2006a,
  author = {Domingo L{\a'o}pez-Rodr{\a'\i}guez and Enrique M{\a'e}rida Casermeiro and Juan Miguel Ortiz-de-Lazcano-Lobato and Ezequiel L{\a'o}pez-Rubio},
  booktitle = {Artificial Neural Networks - {ICANN} 2006, 16th International Conference, Athens, Greece, September 10-14, 2006. Proceedings, Part {II}},
  title = {Image Compression by Vector Quantization with Recurrent Discrete Networks},
  year = {2006},
  address = {Athens},
  editor = {Stefanos D. Kollias and Andreas Stafylopatis and Wlodzislaw Duch and Erkki Oja},
  note = {cited By 6; Conference of 16th International Conference on Artificial Neural Networks, ICANN 2006 ; Conference Date: 10 September 2006 Through 14 September 2006; Conference Code:68317},
  pages = {595--605},
  publisher = {Springer},
  series = {Lecture Notes in Computer Science},
  volume = {4132},
  abstract = {In this work we propose a recurrent multivalued network, generalizing Hopfield's model, which can be interpreted as a vector quantifier. We explain the model and establish a relation between vector quantization and sum-of-squares clustering. To test the efficiency of this model as vector quantifier, we apply this new technique to image compression. Two well-known images are used as benchmark, allowing us to compare our model to standard competitive learning. In our simulations, our new technique clearly outperforms the classical algorithm for vector quantization, achieving not only a better distortion rate, but even reducing drastically the computational time. © Springer-Verlag Berlin Heidelberg 2006.},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/icann/Lopez-RodriguezCOL06.bib},
  document_type = {Conference Paper},
  doi = {10.1007/11840930_62},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {Algorithms; Learning systems; Mathematical models; Recurrent neural networks; Vector quantization, Classical algorithm; Hopfield's model; Sum-of-squares clustering; Vector quantifier, Image compression},
  source = {Scopus},
  url = {https://doi.org/10.1007/11840930_62},
}

@InProceedings{LopezRubio2006a,
  author = {E. L{\a'o}pez-Rubio and J.M. Ortiz-De-Lazcano-Lobato and D. L{\a'o}pez-Rodr{\a'\i}guez and E. M{\a'e}rida-Casermeiro and M. {Del Carmen Vargas-Gonz{\a'a}lez}},
  booktitle = {Artificial Neural Networks - {ICANN} 2006, 16th International Conference, Athens, Greece, September 10-14, 2006. Proceedings, Part {II}},
  title = {Local selection of model parameters in probability density function estimation},
  year = {2006},
  address = {Athens},
  editor = {Stefanos D. Kollias and Andreas Stafylopatis and Wlodzislaw Duch and Erkki Oja},
  note = {cited By 0; Conference of 16th International Conference on Artificial Neural Networks, ICANN 2006 ; Conference Date: 10 September 2006 Through 14 September 2006; Conference Code:68317},
  pages = {292-301},
  publisher = {Springer Verlag},
  series = {Lecture Notes in Computer Science},
  volume = {4132 LNCS - II},
  abstract = {Here we present a novel probability density estimation model. The classical Parzen window approach builds a spherical Gaussian density around every input sample. Our proposal selects a Gaussian specifically tuned for each sample, with an automated estimation of the local intrinsic dimensionality of the embedded manifold and the local noise variance. This leads to outperform other proposals where local parameter selection is not allowed, like the manifold Parzen windows. © Springer-Verlag Berlin Heidelberg 2006.},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/icann/Lopez-RubioOLCV06.bib},
  document_type = {Conference Paper},
  doi = {10.1007/11840930_30},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {Gaussian noise (electronic); Mathematical models; Parameter estimation; Signal noise measurement, Automated estimation; Local intrinsic dimensionality; Local noise variance; Parzen window approach, Probability density function},
  source = {Scopus},
  url = {https://doi.org/10.1007/11840930_30},
}

@InProceedings{mora2006development,
  title = {Development of a virtual learning community for the subject numerical methods under Moodle},
  author = {{\a'A}ngel Mora and E M{\a'e}rida and D L{\a'o}pez-Rodr{\a'\i}guez},
  booktitle = {Current developments in technology assisted education-m-ICTE},
  pages = {361--365},
  year = {2006},
}

@InProceedings{LopezRodriguez2006,
  author = {D. L{\a'o}pez-Rodr{\a'\i}guez and E. M{\a'e}rida-Casermeiro and J.M. Ortiz-De-Lazcano-Lobato},
  booktitle = {International Conference on Computational Intelligence, Man-Machine Systems and Cybernetics - Proceedings},
  title = {Stochastic multivalued network for optimization. Application to the graph MaxCut problem},
  year = {2006},
  editor = {Mastorakis N. {Cecchi A.}},
  note = {cited By 0; Conference of Proceedings of the 5th WSEAS International Conference on Computational Intelligence, Man-Machine Systems and Cybernetics, CIMMACS '06 ; Conference Date: 20 November 2006 Through 22 November 2006; Conference Code:106271},
  pages = {111-116},
  publisher = {World Scientific and Engineering Academy and Society},
  volume = {1},
  abstract = {The aim of this paper is to present the stochastic version of the multivalued neural model MREM, which has achieved very good results in many applications, as an optimization technique. The purpose of this stochastic version is to avoid certain local minima of the objective function minimized by the network, that is, the energy function. To this end, the description of the theoretical bases of this model, guaranteeing the convergence to minima, is carried out rigorously. In order to show the efficiency of this new model, the model, in its two versions, deterministic and stochastic, has been applied to the resolution of the well-known problem of graph partition, MaxCut. Computational experiments show that in most cases the stochastic model achieves better results than the deterministic one.},
  author_keywords = {Graph Problems; Neural Networks; Optimization Problems; Stochastic Dynamics},
  document_type = {Conference Paper},
  keywords = {Artificial intelligence; Interactive computer systems; Neural networks; Optimization; Stochastic models, Computational experiment; Energy functions; Graph problems; Multi-valued networks; Objective functions; Optimization problems; Optimization techniques; Stochastic dynamics, Stochastic systems},
  source = {Scopus},
  sponsors = {WSEAS; WSEAS Transactions},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84905721381&partnerID=40&md5=d3a92408b239ff652b5fbf70437f6200},
}

@InProceedings{mora2007hecacej,
  title = {HECACEJ: B-Learning Tool for Static Content Creation in Joomla!},
  author = {Angel Mora-Bonilla and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Enrique M{\a'e}rida-Casermeiro and Salvador Merino-C{\a'o}rdoba},
  booktitle = {Blended Learning},
  volume = {2007},
  pages = {227--236},
  year = {2007},
}

@InProceedings{domingo2007multivalued,
  title = {A multivalued neural network for the degree-constrained minimum spanning tree problem},
  author = {Domingo L{\a'o}pez-Rodr{\a'\i}guez and Enrique M{\a'e}rida-Casermeiro and Juan Miguel Ortiz-de-Lazcano-Lobato},
  booktitle = {CAEPIA-TTIA 2007: actas},
  pages = {269--278},
  year = {2007},
}

@InProceedings{LopezRodriguez2007b,
  author = {D. L{\a'o}pez-Rodr{\a'\i}guez and E. M{\a'e}rida-Casermeiro and J.M. Ort{\a'\i}z-de-Lazcano-Lobato and G. Gal{\a'a}n-Mar{\a'\i}n},
  booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  title = {K-pages graph drawing with multivalued neural networks},
  year = {2007},
  address = {Porto},
  note = {cited By 7; Conference of 17th International Conference on Artificial Neural Networks, ICANN 2007 ; Conference Date: 9 September 2007 Through 13 September 2007; Conference Code:70943},
  number = {PART 2},
  pages = {816-825},
  publisher = {Springer Verlag},
  volume = {4669 LNCS},
  abstract = {In this paper, the K-pages graph layout problem is solved by a new neural model. This model consists of two neural networks performing jointly in order to minimize the same energy function. The neural technique applied to this problem allows to reduce the energy function by changing outputs from both networks -outputs of first network representing location of nodes in the nodes line, while the outputs of the second one meaning the page where the edges are drawn. A detailed description of the model is presented, and the technique to minimize an energy function is fully described. It has proved to be a very competitive and efficient algorithm, in terms of quality of solutions and computational time, when compared to the state-of-the-art heuristic methods specifically designed for this problem. Some simulation results are presented in this paper, to show the comparative efficiency of the methods. © Springer-Verlag Berlin Heidelberg 2007.},
  document_type = {Conference Paper},
  doi = {10.1007/978-3-540-74695-9_84},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {Algorithms; Edge detection; Function evaluation; Graph theory; Heuristic methods; Mathematical models, Efficient algorithms; Energy functions; Multivalued neural networks; Neural models, Multilayer neural networks},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-38149053100&doi=10.1007%2f978-3-540-74695-9_84&partnerID=40&md5=7233c2564e713f2a8c63119b2fbc9ed9},
}

@InProceedings{LopezRubio2007,
  author = {Ezequiel L{\a'o}pez-Rubio and Juan Miguel Ortiz-de-Lazcano-Lobato and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Mar{\a'\i}a {del Carmen Vargas-Gonz{\a'a}lez}},
  booktitle = {Artificial Neural Networks - {ICANN} 2007, 17th International Conference, Porto, Portugal, September 9-13, 2007, Proceedings, Part {I}},
  title = {Soft Clustering for Nonparametric Probability Density Function Estimation},
  year = {2007},
  address = {Porto},
  editor = {Joaquim Marques {de {\a'a}} and Lu{\a'\i}s A. Alexandre and Wlodzislaw Duch and Danilo P. Mandic},
  note = {cited By 0; Conference of 17th International Conference on Artificial Neural Networks, ICANN 2007 ; Conference Date: 9 September 2007 Through 13 September 2007; Conference Code:70943},
  number = {PART 1},
  pages = {707-716},
  publisher = {Springer Verlag},
  series = {Lecture Notes in Computer Science},
  volume = {4668 LNCS},
  abstract = {We present a nonparametric probability density estimation model. The classical Parzen window approach builds a spherical Gaussian density around every input sample. Our method has a first stage where hard neighbourhoods are determined for every sample. Then soft clusters are considered to merge the information coming from several hard neighbourhoods. Our proposal estimates the local principal directions to yield a specific Gaussian mixture component for each soft cluster. This leads to outperform other proposals where local parameter selection is not allowed and/or there are no smoothing strategies, like the manifold Parzen windows. © Springer-Verlag Berlin Heidelberg 2007.},
  author_keywords = {Nonparametric modeling; Parzen windows; Probability density estimation; Soft clustering},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/icann/Lopez-RubioOLV07.bib},
  document_type = {Conference Paper},
  doi = {10.1007/978-3-540-74690-4_72},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  source = {Scopus},
  url = {https://doi.org/10.1007/978-3-540-74690-4_72},
}

@InProceedings{GalanMarin2007a,
  author = {G. Gal{\a'a}n-Mar{\a'\i}n and E. M{\a'e}rida-Casermeiro and D. L{\a'o}pez-Rodr{\a'\i}guez and J.M. Ortiz-De-Lazcano-Lobato},
  booktitle = {Adaptive and Natural Computing Algorithms, 8th International Conference, {ICANNGA} 2007, Warsaw, Poland, April 11-14, 2007, Proceedings, Part {II}},
  title = {A Study into the Improvement of Binary Hopfield Networks for Map Coloring},
  year = {2007},
  address = {Warsaw},
  editor = {Bartlomiej Beliczynski and Andrzej Dzielinski and Marcin Iwanowski and Bernardete Ribeiro},
  note = {cited By 3; Conference of 8th International Conference on Adaptive and Natural Computing Algorithms, ICANNGA 2007 ; Conference Date: 11 April 2007 Through 14 April 2007; Conference Code:71057},
  number = {PART 2},
  pages = {98-106},
  publisher = {Springer Verlag},
  series = {Lecture Notes in Computer Science},
  volume = {4432 LNCS},
  abstract = {The map-coloring problem is a well known combinatorial optimization problem which frequently appears in mathematics, graph theory and artificial intelligence. This paper presents a study into the performance of some binary Hopfield networks with discrete dynamics for this classic problem. A number of instances have been simulated to demonstrate that only the proposed binary model provides optimal solutions. In addition, for large-scale maps an algorithm is presented to improve the local minima of the network by solving gradually growing submaps of the considered map. Simulation results for several n-region 4-color maps showed that the proposed neural algorithm converged to a correct colouring from at least 90% of initial states without the fine-tuning of parameters required in another Hopfield models. © Springer-Verlag Berlin Heidelberg 2007.},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/icannga/MarinCLO07.bib},
  document_type = {Conference Paper},
  doi = {10.1007/978-3-540-71629-7_12},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {Coloring; Graph theory; Large scale systems; Optimization; Problem solving, Classic problems; Large-scale maps; Map coloring, Hopfield neural networks},
  source = {Scopus},
  url = {https://doi.org/10.1007/978-3-540-71629-7_12},
}

@InProceedings{Casermeiro2007b,
  author = {Enrique M{\a'e}rida Casermeiro and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Gloria Gal{\a'a}n Mar{\a'\i}n and Juan Miguel Ortiz-de-Lazcano-Lobato},
  booktitle = {Adaptive and Natural Computing Algorithms, 8th International Conference, {ICANNGA} 2007, Warsaw, Poland, April 11-14, 2007, Proceedings, Part {I}},
  title = {Improved Production of Competitive Learning Rules with an Additional Term for Vector Quantization},
  year = {2007},
  address = {Warsaw},
  editor = {Bartlomiej Beliczynski and Andrzej Dzielinski and Marcin Iwanowski and Bernardete Ribeiro},
  note = {cited By 1; Conference of 8th International Conference on Adaptive and Natural Computing Algorithms, ICANNGA 2007 ; Conference Date: 11 April 2007 Through 14 April 2007; Conference Code:71057},
  number = {PART 1},
  pages = {461--469},
  publisher = {Springer},
  series = {Lecture Notes in Computer Science},
  volume = {4431},
  abstract = {In this work, a general framework for developing learning rules with an added term (perturbation term) is presented. Many learning rules commonly cited in the specialized literature can be derived from this general framework. This framework allows us to introduce some knowledge about vector quantization (as an optimization problem) in the distortion function in order to derive a new learning rule that uses that information to avoid certain local minima of the distortion function, leading to better performance than classical models. Computational experiments in image compression show that our proposed rule, derived from this general framework, can achieve better results than simple competitive learning and other models, with codebooks of less distortion. © Springer-Verlag Berlin Heidelberg 2007.},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/icannga/CasermeiroLMO07.bib},
  document_type = {Conference Paper},
  doi = {10.1007/978-3-540-71618-1_51},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {Mathematical models; Perturbation techniques; Vector quantization, Competitive learning; Distortion function; Learning rules; Specialized literature, Learning systems},
  source = {Scopus},
  url = {https://doi.org/10.1007/978-3-540-71618-1_51},
}

@InProceedings{Casermeiro2007c,
  author = {Enrique M{\a'e}rida Casermeiro and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Juan Miguel Ortiz-de-Lazcano-Lobato},
  booktitle = {Artificial Intelligence and Innovations 2007: from Theory to Applications, Proceedings of the 4th {IFIP} International Conference on Artificial Intelligence Applications and Innovations {(AIAI} 2007), 19-21 September 2007, Peania, Athens, Greece},
  title = {Image Compression with Competitive Networks and Pre-fixed Prototypes},
  year = {2007},
  editor = {Christos Boukis and Aristodemos Pnevmatikakis and Lazaros Polymenakos},
  note = {cited By 0},
  pages = {339--346},
  publisher = {Springer},
  series = {{IFIP}},
  volume = {247},
  abstract = {Image compression techniques have required much attention from the neural networks community for the last years. In this work we intend to develop a new algorithm to perform image compression based on adding some pre-fixed prototypes to those obtained by a competitive neural network. Prototypes are selected to get a better representation of the compressed image, improving the computational time needed to encode the image and decreasing the code-book storage necessities of the standard approach. This new method has been tested with some well-known images and results proved that our proposal outperforms classical methods in terms of maximizing peak-signal-to-noise-ratio values. © 2007 International Federation for Information Processing.},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/ifip12/CasermeiroLO07.bib},
  document_type = {Conference Paper},
  doi = {10.1007/978-0-387-74161-1\_37},
  journal = {IFIP International Federation for Information Processing},
  keywords = {Image compression; Image quality, Classical methods; Competitive network; Competitive neural network; Compressed images; Computational time; Image compression techniques; Peak signal to noise ratio, Artificial intelligence},
  source = {Scopus},
  url = {https://doi.org/10.1007/978-0-387-74161-1_37},
}

@InProceedings{LopezRubio2007b,
  author = {E. L{\a'o}pez-Rubio and J.M. Ortiz-De-Lazcano-Lobato and D. L{\a'o}pez-Rodr{\a'\i}guez and M. {Del Carmen Vargas-Gonz{\a'a}lez}},
  booktitle = {Computational and Ambient Intelligence, 9th International Work-Conference on Artificial Neural Networks, {IWANN} 2007, San Sebastián, Spain, June 20-22, 2007, Proceedings},
  title = {Automatic Model Selection for Probabilistic {PCA}},
  year = {2007},
  address = {San Sebastian},
  editor = {Francisco Sandoval Hern{\a'a}ndez and Alberto Prieto and Joan Cabestany and Manuel Gra~na},
  note = {cited By 0; Conference of 9th International Work-Conference on Artificial Neural Networks, IWANN 2007 ; Conference Date: 20 June 2007 Through 22 June 2007; Conference Code:71094},
  pages = {127-134},
  publisher = {Springer Verlag},
  series = {Lecture Notes in Computer Science},
  volume = {4507 LNCS},
  abstract = {The Mixture of Probabilistic Principal Components Analyzers (MPPCA) is a multivariate analysis technique which defines a Gaussian probabilistic model at each unit. The number of units and principal directions in each unit is not learned in the original approach. Variational Bayesian approaches have been proposed for this purpose, which rely on assumptions on the input distribution and/or approximations of certain statistics. Here we present a different way to solve this problem, where cross-validation is used to guide the search for an optimal model selection. This allows to learn the model architecture without the need of any assumptions other than those of the basic PPCA framework. Experimental results are presented, which show the probability density estimation capabilities of the proposal with high dimensional data. © Springer-Verlag Berlin Heidelberg 2007.},
  author_keywords = {Cross-validation; Dimensionality reduction; Handwritten digit recognition; Probabilistic Principal Components Analysis (PPCA)},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/iwann/Lopez-RubioOLV07.bib},
  document_type = {Conference Paper},
  doi = {10.1007/978-3-540-73007-1_16},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {Approximation theory; Bayesian networks; Gaussian distribution; Mathematical models; Probability density function, Multivariate analysis; Optimal model selection, Principal component analysis},
  source = {Scopus},
  url = {https://doi.org/10.1007/978-3-540-73007-1_16},
}

@InProceedings{LopezRubio2007a,
  author = {E. L{\a'o}pez-Rubio and J.M. Ortiz-De-Lazcano-Lobato and D. L{\a'o}pez-Rodr{\a'\i}guez and M. {Del Carmen Vargas-Gonz{\a'a}lez}},
  booktitle = {Computational and Ambient Intelligence, 9th International Work-Conference on Artificial Neural Networks, {IWANN} 2007, San Sebastián, Spain, June 20-22, 2007, Proceedings},
  title = {Self-organization of probabilistic PCA models},
  year = {2007},
  address = {San Sebastian},
  editor = {Francisco Sandoval Hern{\a'a}ndez and Alberto Prieto and Joan Cabestany and Manuel Gra~na},
  note = {cited By 1; Conference of 9th International Work-Conference on Artificial Neural Networks, IWANN 2007 ; Conference Date: 20 June 2007 Through 22 June 2007; Conference Code:71094},
  pages = {211-218},
  publisher = {Springer Verlag},
  series = {Lecture Notes in Computer Science},
  volume = {4507 LNCS},
  abstract = {We present a new neural model, which extends Kohonen's self-organizing map (SOM) by performing a Probabilistic Principal Components Analysis (PPCA) at each neuron. Several self-organizing maps have been proposed in the literature to capture the local principal subspaces, but our approach offers a probabilistic model at each neuron while it has linear complexity on the dimensionality of the input space. This allows to process very high dimensional data to obtain reliable estimations of the local probability densities which are based on the PPCA framework. Experimental results are presented, which show the map formation capabilities of the proposal with high dimensional data. © Springer-Verlag Berlin Heidelberg 2007.},
  author_keywords = {Competitive learning; Dimensionality reduction; Face recognition; Handwritten digit recognition; Probabilistic Principal Components Analysis (PPCA); Unsupervised learning},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/iwann/Lopez-RubioOLV07a.bib},
  document_type = {Conference Paper},
  doi = {10.1007/978-3-540-73007-1_26},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {Computational complexity; Face recognition; Mathematical models; Probability density function; Self organizing maps; Unsupervised learning, Competitive learning; Dimensionality reduction; Handwritten digit recognition; Linear complexity; Probabilistic model; Probabilistic Principal Components Analysis (PPCA), Principal component analysis},
  source = {Scopus},
  url = {https://doi.org/10.1007/978-3-540-73007-1_26},
}

@InProceedings{LopezRodriguez2007c:1,
  author = {D. L{\a'o}pez-Rodr{\a'\i}guez and E. M{\a'e}rida-Casermeiro and J.M. Ort{\a'\i}z-De-Lazcano-Lobato and G. Gal{\a'a}n-Mar{\a'\i}n},
  booktitle = {Computational and Ambient Intelligence, 9th International Work-Conference on Artificial Neural Networks, {IWANN} 2007, San Sebastián, Spain, June 20-22, 2007, Proceedings},
  title = {Two pages graph layout via recurrent multivalued neural networks},
  year = {2007},
  address = {San Sebastian},
  editor = {Francisco Sandoval Hern{\a'a}ndez and Alberto Prieto and Joan Cabestany and Manuel Gra~na},
  note = {cited By 0; Conference of 9th International Work-Conference on Artificial Neural Networks, IWANN 2007 ; Conference Date: 20 June 2007 Through 22 June 2007; Conference Code:71094},
  pages = {194-202},
  publisher = {Springer Verlag},
  series = {Lecture Notes in Computer Science},
  volume = {4507 LNCS},
  abstract = {In this work, we propose the use of two neural models performing jointly in order to minimize the same energy function. This model is focused on obtaining good solutions for the two pages book crossing problem, although some others problems can be efficiently solved by the same model. The neural technique applied to this problem allows to reduce the energy function by changing outputs from both networks -outputs of first network representing location of nodes in the nodes line, while the outputs of the second one meaning the half-plane where the edges are drawn. Detailed description of the model is presented, and the technique to minimize an energy function is fully described. It has proved to be a very competitive and efficient algorithm, in terms of quality of solutions and computational time, when compared to the state-of-the-art methods. Some simulation results are presented in this paper, to show the comparative efficiency of the methods. © Springer-Verlag Berlin Heidelberg 2007.},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/iwann/Lopez-RodriguezCOM07.bib},
  document_type = {Conference Paper},
  doi = {10.1007/978-3-540-73007-1_24},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {Algorithms; Computer simulation; Graph theory; Mathematical models; Problem solving, Computational time; Energy function, Recurrent neural networks},
  source = {Scopus},
  url = {https://doi.org/10.1007/978-3-540-73007-1_24},
}

@InProceedings{Casermeiro2007d,
  author = {Enrique M{\a'e}rida Casermeiro and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Gloria Gal{\a'a}n Mar{\a'\i}n and Juan Miguel Ortiz-de-Lazcano-Lobato},
  booktitle = {Bio-inspired Modeling of Cognitive Tasks, Second International Work-Conference on the Interplay Between Natural and Artificial Computation, {IWINAC} 2007, La Manga del Mar Menor, Spain, June 18-21, 2007, Proceedings, Part {I}},
  title = {Theoretical Study on the Capacity of Associative Memory with Multiple Reference Points},
  year = {2007},
  address = {La Manga del Mar Menor},
  editor = {Jos{\a'e} Mira and Jos{\a'e} R. {\a'A}lvarez},
  note = {cited By 0; Conference of 2nd International Work-Conference on the Interplay Between Natural and Artificial Computation, IWINAC 2007 ; Conference Date: 18 June 2007 Through 21 June 2007; Conference Code:70787},
  number = {PART 1},
  pages = {292--302},
  publisher = {Springer},
  series = {Lecture Notes in Computer Science},
  volume = {4527},
  abstract = {An extension to Hopfield's model of associative memory is studied in the present work. In particular, this paper is focused in giving solutions to the two main problems present in the model: the apparition of spurious patterns in the learning phase (implying the well-known and undesirable effect of storing the opposite pattern) and the problem of its reduced capacity (the probability of error in the retrieving phase increases as the number of stored patterns grows). In this work, a method to avoid spurious patterns is presented and studied, and an explanation to the previously mentioned effect is given. Another novel technique to increase the capacity of a network is proposed here, based on the idea of using several reference points when storing patterns. It is studied in depth, and an explicit formula for the capacity of the network is provided. This formula shows the linear dependence of the capacity of the new model on the number of reference points, implying the increase of the capacity in mis model. © Springer-Verlag Berlin Heidelberg 2007.},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/iwinac/CasermeiroLMO07.bib},
  document_type = {Conference Paper},
  doi = {10.1007/978-3-540-73053-8_29},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {Learning systems; Pattern recognition; Probability; Problem solving, Linear dependence; Reference points, Computation theory},
  source = {Scopus},
  url = {https://doi.org/10.1007/978-3-540-73053-8_29},
}

@InProceedings{LopezRodriguez2007a,
  author = {D. L{\a'o}pez-Rodr{\a'\i}guez and E. M{\a'e}rida-Casermeiro and G. Gal{\a'a}n-Mar{\a'\i}n and J.M. Ortiz-de-Lazcano-Lobato},
  booktitle = {{KI} 2007: Advances in Artificial Intelligence, 30th Annual German Conference on AI, {KI} 2007, Osnabr{\"{u}}ck, Germany, September 10-13, 2007, Proceedings},
  title = {Stochastic functional annealing as optimization technique: Application to the traveling salesman problem with recurrent networks},
  year = {2007},
  address = {Osnabruck},
  editor = {Joachim Hertzberg and Michael Beetz and Roman Englert},
  note = {cited By 0; Conference of 30th Annual German Conference on Artificial Intelligence, KI 2007 ; Conference Date: 10 September 2007 Through 13 September 2007; Conference Code:70942},
  pages = {397-411},
  publisher = {Springer Verlag},
  series = {Lecture Notes in Computer Science},
  volume = {4667 LNAI},
  abstract = {In this work, a new stochastic method for optimization problems is developed. Its theoretical bases guaranteeing the convergence of the method to a minimum of the objective function are presented, by using quite general hypotheses. Its application to recurrent discrete neural networks is also developed, focusing in the multivalued MREM model, a generalization of Hopfield's. In order to test the efficiency of this new method, we study the well-known Traveling Salesman Problem. Experimental results will show that this new model outperforms other techniques, achieving better results, even on average, than other methods. © Springer-Verlag Berlin Heidelberg 2007.},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/ki/Lopez-RodriguezCMO07.bib},
  document_type = {Conference Paper},
  doi = {10.1007/978-3-540-74565-5_30},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {Computational efficiency; Convergence of numerical methods; Finite difference method; Hopfield neural networks; Traveling salesman problem, Discrete neural networks; Stochastic functional annealing; Stochastic methods, Stochastic models},
  source = {Scopus},
  url = {https://doi.org/10.1007/978-3-540-74565-5_30},
}

@InProceedings{maxcut,
  title = {Red Multivaluada Estocástica para Optimización. Aplicación al Problema del MaxCut},
  author = {Juan Miguel Ortiz de Lazcano Lobato { Domingo L{\a'o}pez Rodr{\a'\i}guez Enrique M{\a'e}rida Casermeiro}},
  booktitle = { Actas del V Congreso Español sobre Metaheurísticas, Algoritmos Evolutivos y Bioinspirados},
  pages = {85--90},
  year = {2007},
}

@InProceedings{merida2008adjust,
  title = {Adjust of Contradictory Information by a Fuzzy Method},
  author = {E. M{\a'e}rida-Casermeiro and D. L{\a'o}pez-Rodr{\a'\i}guez},
  booktitle = {Proceedings of the 2008 International Conference on Computational and Mathematical Methods in Science and Engineering},
  pages = {439--451},
  year = {2008},
}

@InProceedings{Cordoba2008,
  author = {S.M. C{\a'o}rdoba and J.M. {Del Castillo} and G.G. Barranco and A. Mora-Bonilla and D. L{\a'o}pez-Rodr{\a'\i}guez and E. M{\a'e}rida-Casermeiro},
  booktitle = {Proceedings of the IASTED International Conference on Internet and Multimedia Systems and Applications and Visual Communications},
  title = {Fnova: Fermat and joomla fusion},
  year = {2008},
  address = {Innsbruck},
  note = {cited By 0; Conference of IASTED International Conference on Internet and Multimedia Systems and Applications and Visual Communications ; Conference Date: 17 March 2008 Through 18 March 2008; Conference Code:75520},
  pages = {15-20},
  abstract = {We present a work developed by a group of teachers in the Department of Applied Mathematics at the University of Malaga. Since 2002, FERMAT1 Project has become an important meeting point between teachers and students for the subjects of Numerical Methods, Algebra, Calculus, Vectorial Analysis, Differential Equations and Discrete Mathematics in the degree of Telecommunication Engineering. Our main goal was the development of an educational environment complementary to the classical model of teaching, in order to get a gradual adaptation to the European Space for Higher Education (ESHE) according to Bologna Declaration. Our method consists on theoretical lessons using multimedia technologies and also practical sessions in the laboratories. In these sessions the students solve practical problems with the aid of the computer. On the other hand, we offer access to the resources in our website (class notes, proposed and solved problems...), an also to on-line resources: mail, forum, chat, videoconference... In a first step we create FERMAT website including some resources that can be useful for students. The suggestions of these students have been helpful for the development of the last version, named FNOVA2. Thanks to these suggestions we have introduced important improvements in this version of our new tool3. These are those that we present in this paper.},
  author_keywords = {E-learning; ESHE; Joomla!; Mathematics; Moodle},
  document_type = {Conference Paper},
  keywords = {Applied mathematics; Bologna declarations; Class notes; Classical models; Discrete mathematics; Educational environments; ESHE; Higher educations; Joomla!; Mathematics; Moodle; Multi-media technologies; New tools; On-line resources; Practical problems; Telecommunication engineerings; Vectorial analysis; Web sites, Algebra; Communication; Differentiation (calculus); E-learning; Education computing; Image communication systems; Internet; Motion compensation; Numerical methods; Students; Teaching; Visual communication; World Wide Web, Multimedia systems},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-62649128925&partnerID=40&md5=b408a2435f4dd334f12eacb6e63a8b50},
}

@InProceedings{DBLP:conf/his/LuqueLCP08,
  author = {Rafael Marcos Luque and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Enrique M{\a'e}rida Casermeiro and Esteban J. Palomo},
  editor = {Fatos Xhafa and Francisco Herrera and Ajith Abraham and Mario K{\"o}ppen and Jos{\a'e} Manuel Ben{\a'\i}tez},
  title = {Video Object Segmentation with Multivalued Neural Networks},
  booktitle = {8th International Conference on Hybrid Intelligent Systems {(HIS}
               2008), September 10-12, 2008, Barcelona, Spain},
  pages = {613--618},
  publisher = {{IEEE} Computer Society},
  year = {2008},
  url = {https://doi.org/10.1109/HIS.2008.130},
  doi = {10.1109/HIS.2008.130},
  timestamp = {Wed, 16 Oct 2019 14:14:55 +0200},
  biburl = {https://dblp.org/rec/conf/his/LuqueLCP08.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
}

@InProceedings{Casermeiro2008,
  author = {Enrique M{\a'e}rida Casermeiro and Domingo L{\a'o}pez-Rodr{\a'\i}guez},
  booktitle = {8th International Conference on Hybrid Intelligent Systems {(HIS} 2008), September 10-12, 2008, Barcelona, Spain},
  title = {Drawing Graphs in Parallel Lines with Artificial Neural Networks},
  year = {2008},
  address = {Barcelona},
  editor = {Fatos Xhafa and Francisco Herrera and Ajith Abraham and Mario K{\"o}ppen and Jos{\a'e} Manuel Ben{\a'\i}tez},
  note = {cited By 0; Conference of 8th International Conference on Hybrid Intelligent Systems, HIS 2008 ; Conference Date: 10 September 2008 Through 12 September 2008; Conference Code:73852},
  pages = {667--671},
  publisher = {{IEEE} Computer Society},
  abstract = {In this work, we propose the use of a multivalued recurrent neural network with the aim of graph drawing. Particularly, the problem of drawing a graph in two parallel lines with the minimum number of crossings between edges is studied, and a formulation for this problem is presented. The neural model MREM is used to solve this problem. This model has been successfully applied to other optimization problems. In this case, a slightly different version is used, in which the neuron state is represented by a two dimensional discrete vector, representing the nodes assigned to a given position in each of the parallel lines. Some experimental simulations have been carried out in order to compare the efficiency of the neural network with a heuristic approach designed to solve the problem at hand. These simulations confirm that our neural model outperforms the heuristic approach, obtaining a lower number of crossings on average. © 2008 IEEE.},
  art_number = {4626707},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/his/Merida-CasermeiroL08.bib},
  document_type = {Conference Paper},
  doi = {10.1109/HIS.2008.89},
  journal = {Proceedings - 8th International Conference on Hybrid Intelligent Systems, HIS 2008},
  keywords = {Drawing (graphics); Graph theory; Heuristic methods; Image classification; Intelligent control; Intelligent systems; Problem solving; Recurrent neural networks; Vegetation, Artificial neural networks; Discrete vectors; Experimental simulations; Heuristic approaches; Neural models; Of graphs; Optimization problems; Parallel lines, Neural networks},
  source = {Scopus},
  sponsors = {IEEE Systems Man and Cybernetics Society; European Neural Network Society; International Fuzzy Systems Association; European Society for Fuzzy Logic and Technology},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-55349109310&doi=10.1109%2fHIS.2008.89&partnerID=40&md5=d3db07ff7d48861d1a455b54dd5c20db},
}

@InProceedings{Bonilla2008a,
  author = {Angel Mora Bonilla and Enrique M{\a'e}rida Casermeiro and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Luis Fernando L{\a'o}pez Anguita},
  booktitle = {{IADIS} International Conference e-Learning 2008, Amsterdam, The Netherlands, July 22-25, 2008. Proceedings},
  title = {Integration Of Moodle Quizzes},
  year = {2008},
  editor = {Miguel Baptista Nunes and Maggie McPherson},
  pages = {45--52},
  publisher = {{IADIS}},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/iadis/BonillaCLA08.bib},
}

@InProceedings{Luque2008,
  author = {Rafael Marcos Luque and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Enrique Dom{\a'\i}nguez and Esteban J. Palomo},
  booktitle = {Advances in Artificial Intelligence - {IBERAMIA} 2008, 11th Ibero-American Conference on AI, Lisbon, Portugal, October 14-17, 2008. Proceedings},
  title = {A Dipolar Competitive Neural Network for Video Segmentation},
  year = {2008},
  address = {Lisbon},
  editor = {Hector Geffner and Rui Prada and Isabel Machado Alexandre and Nuno David},
  note = {cited By 5; Conference of 11th Ibero-American Conference on Artificial Intelligence, IBERAMIA 2008 ; Conference Date: 14 October 2008 Through 17 October 2008; Conference Code:77561},
  pages = {103-112},
  publisher = {Springer},
  series = {Lecture Notes in Computer Science},
  volume = {5290 LNAI},
  abstract = {This paper present a video segmentation method which separate pixels corresponding to foreground from those corresponding to background. The proposed background model consists of a competitive neural network based on dipoles, which is used to classify the pixels as background or foreground. Using this kind of neural networks permits an easy hardware implementation to achieve a real time processing with good results. The dipolar representation is designed to deal with the problem of estimating the directionality of data. Experimental results are provided by using the standard PETS dataset and compared with the mixture of Gaussians and background subtraction methods. © 2008 Springer-Verlag.},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/iberamia/LuqueLDP08.bib},
  document_type = {Conference Paper},
  doi = {10.1007/978-3-540-88309-8_11},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {Background model; Background subtraction method; Competitive neural network; Data sets; Hardware implementations; Mixture of Gaussians; Realtime processing; Video segmentation, Hardware; Image segmentation; Pixels, Neural networks},
  source = {Scopus},
  sponsors = {Lisbon University Institute (ISCTE); Fundacao para a Ciencia e Tecnologia (FCT); Asociacion Espanola de Inteligencia Artificial (AEPIA); Associacao Portuguesa para a Inteligencia Artificial (APPIA)},
  url = {https://doi.org/10.1007/978-3-540-88309-8_11},
}

@InProceedings{Baena2008a,
  author = {R.M. {Luque Baena} and E. Dominguez and D. L{\a'o}pez-Rodr{\a'\i}guez and E.J. Palomo},
  booktitle = {Artificial Neural Networks - {ICANN} 2008 , 18th International Conference, Prague, Czech Republic, September 3-6, 2008, Proceedings, Part {I}},
  title = {A Neighborhood-Based Competitive Network for Video Segmentation and Object Detection},
  year = {2008},
  address = {Prague},
  editor = {Vera Kurko {\a'a} and Roman Neruda and Jan Koutn{\a'\i}k},
  note = {cited By 2; Conference of 18th International Conference on Artificial Neural Networks, ICANN 2008 ; Conference Date: 3 September 2008 Through 6 September 2008; Conference Code:73798},
  number = {PART 1},
  pages = {877--886},
  publisher = {Springer},
  series = {Lecture Notes in Computer Science},
  volume = {5163},
  abstract = {This work proposes an unsupervised competitive neural network based on adaptive neighborhoods for video segmentation and object detection. The designed neural network is proposed to form a background model based on subtraction approach. The synaptic weights and the adaptive neighborhood of the neurons serve as a model of the background and are updated to reflect the statistics of the background. The segmentation performance of the proposed neural network is examined and compared to mixture of Gaussian models. The proposed algorithm is parallelized on a pixel level and designed to enable efficient hardware implementation to achieve real-time processing at great frame rates. © Springer-Verlag Berlin Heidelberg 2008.},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/icann/BaenaDLP08.bib},
  document_type = {Conference Paper},
  doi = {10.1007/978-3-540-87536-9_90},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {Adaptive neighborhood; Background model; Competitive network; Competitive neural network; Frame rate; Hardware implementations; Mixture of Gaussians; Object Detection; Pixel level; Realtime processing; Segmentation performance; Synaptic weight; Video segmentation, Algorithms; Backpropagation; Hardware; Image segmentation, Neural networks},
  source = {Scopus},
  url = {https://doi.org/10.1007/978-3-540-87536-9_90},
}

@InProceedings{LopezRubio2008,
  author = {E. L{\a'o}pez-Rubio and J.M. Ortiz-De-Lazcano-Lobato and D. L{\a'o}pez-Rodr{\a'\i}guez and M. {Del Carmen Vargas-Gonzalez}},
  booktitle = {Artificial Neural Networks - {ICANN} 2008 , 18th International Conference, Prague, Czech Republic, September 3-6, 2008, Proceedings, Part {I}},
  title = {Robust nonparametric probability density estimation by soft clustering},
  year = {2008},
  address = {Prague},
  editor = {Vera Kurko {\a'a} and Roman Neruda and Jan Koutn{\a'\i}k},
  note = {cited By 0; Conference of 18th International Conference on Artificial Neural Networks, ICANN 2008 ; Conference Date: 3 September 2008 Through 6 September 2008; Conference Code:73798},
  number = {PART 1},
  pages = {155-164},
  publisher = {Springer},
  series = {Lecture Notes in Computer Science},
  volume = {5163 LNCS},
  abstract = {A method to estimate the probability density function of multivariate distributions is presented. The classical Parzen window approach builds a spherical Gaussian density around every input sample. This choice of the kernel density yields poor robustness for real input datasets. We use multivariate Student-t distributions in order to improve the adaptation capability of the model. Our method has a first stage where hard neighbourhoods are determined for every sample. Then soft clusters are considered to merge the information coming from several hard neighbourhoods. Hence, a specific mixture component is learned for each soft cluster. This leads to outperform other proposals where the local kernel is not as robust and/or there are no smoothing strategies, like the manifold Parzen windows. © Springer-Verlag Berlin Heidelberg 2008.},
  bibsource = {dblp computer science bibliography, https://dblp.org},
  biburl = {https://dblp.org/rec/conf/icann/Lopez-RubioOLV08.bib},
  document_type = {Conference Paper},
  doi = {10.1007/978-3-540-87536-9_17},
  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords = {Data sets; Gaussian density; Input sample; Kernel density; Local kernel; Mixture components; Multivariate distributions; Multivariate Student; Non-parametric; Parzen windows; Probability density estimation; Soft clustering, Backpropagation; Neural networks; Probability distributions; Windows, Probability density function},
  source = {Scopus},
  url = {https://doi.org/10.1007/978-3-540-87536-9_17},
}

@InProceedings{novel,
  title = {A Novel Competitive Network Approach to Object Tracking},
  author = {Juan M Ortiz-de-Lazcano-Lobato and Rafael M Luque and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Esteban J Palomo},
  booktitle = {Proceedings of the 2008 UK Workshop on Computational Intelligence},
  pages = {111--116},
  year = {2008},
}

@InProceedings{Iso2008,
  title = {A generalization of the Hopfield model for the graph isomorphism problem},
  author = {Gloria Gal{\a'a}n-Mar{\a'\i}n and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Enrique M{\a'e}rida-Casermeiro},
  booktitle = {Computing and Computational Techniques in Sciences, 2008},
  pages = {98--100},
  year = {2008},
  organization = {WSEAS},
}

@InProceedings{Lopez-RodriguezM09,
  author = {Domingo L{\a'o}pez-Rodr{\a'\i}guez and Enrique M{\a'e}rida Casermeiro},
  editor = {Mikko Kolehmainen and Pekka J. Toivanen and Bartlomiej Beliczynski},
  title = {Shortest Common Superstring Problem with Discrete Neural Networks},
  booktitle = {Adaptive and Natural Computing Algorithms, 9th International Conference,
               {ICANNGA} 2009, Kuopio, Finland, April 23-25, 2009, Revised Selected
               Papers},
  series = {Lecture Notes in Computer Science},
  volume = {5495},
  pages = {62--71},
  publisher = {Springer},
  year = {2009},
  url = {https://doi.org/10.1007/978-3-642-04921-7\_7},
  doi = {10.1007/978-3-642-04921-7\_7},
  timestamp = {Tue, 14 May 2019 10:00:51 +0200},
  biburl = {https://dblp.org/rec/conf/icannga/Lopez-RodriguezM09.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
}

@InProceedings{OLLP09,
  author = {Juan Miguel Ortiz-de-Lazcano-Lobato and Rafael Marcos Luque and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Esteban J. Palomo},
  editor = {Mikko Kolehmainen and Pekka J. Toivanen and Bartlomiej Beliczynski},
  title = {Growing Competitive Network for Tracking Objects in Video Sequences},
  booktitle = {Adaptive and Natural Computing Algorithms, 9th International Conference, {ICANNGA} 2009, Kuopio, Finland, April 23-25, 2009, Revised Selected Papers},
  series = {Lecture Notes in Computer Science},
  volume = {5495},
  pages = {109--118},
  publisher = {Springer},
  year = {2009},
  url = {https://doi.org/10.1007/978-3-642-04921-7\_12},
  doi = {10.1007/978-3-642-04921-7_12},
}

@InProceedings{PalomoOLL09,
  author = {Esteban J. Palomo and Juan Miguel Ortiz-de-Lazcano-Lobato and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Rafael Marcos Luque},
  editor = {Joan Cabestany and Francisco Sandoval Hern{\a'a}ndez and Alberto Prieto and Juan M. Corchado},
  title = {Hierarchical Graphs for Data Clustering},
  booktitle = {Bio-Inspired Systems: Computational and Ambient Intelligence, 10th
               International Work-Conference on Artificial Neural Networks, {IWANN}
               2009, Salamanca, Spain, June 10-12, 2009. Proceedings, Part {I}},
  series = {Lecture Notes in Computer Science},
  volume = {5517},
  pages = {432--439},
  publisher = {Springer},
  year = {2009},
  url = {https://doi.org/10.1007/978-3-642-02478-8\_54},
  doi = {10.1007/978-3-642-02478-8\_54},
  timestamp = {Fri, 06 Dec 2019 09:55:14 +0100},
  biburl = {https://dblp.org/rec/conf/iwann/PalomoOLL09.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
}

@InProceedings{BonillaCL10,
  author = {Angel Mora Bonilla and Enrique M{\a'e}rida Casermeiro and Domingo L{\a'o}pez-Rodr{\a'\i}guez},
  editor = {Joaquim Filipe and Jos{\a'e} Cordeiro},
  title = {Improving Moodle with {WIRIS} and {M-QIT}},
  booktitle = {{ICEIS} 2010 - Proceedings of the 12th International Conference on
               Enterprise Information Systems, Volume 4, SAIC, Funchal, Madeira,
               Portugal, June 8 - 12, 2010},
  pages = {75--80},
  publisher = {SciTePress},
  year = {2010},
  timestamp = {Tue, 04 Jan 2011 09:39:17 +0100},
  biburl = {https://dblp.org/rec/conf/iceis/BonillaCL10.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
}

@InProceedings{lopez2014predictive,
  title = {Predictive and Populational Model for Alzheimer’s Disease Using Structural Neuroimaging},
  author = {D L{\a'o}pez-Rodr{\a'\i}guez and A Garc{\a'\i}a-Linares},
  booktitle = {XIII Mediterranean Conference on Medical and Biological Engineering and Computing 2013},
  pages = {285--288},
  year = {2014},
  organization = {Springer},
}

@InProceedings{PerezGamez2020,
  author = {F. P{\a'e}rez-G{\a'a}mez and M. Ojeda-Hern{\a'a}ndez and {\a'A}. Mora-Bonilla and D. L{\a'o}pez-Rodr{\a'\i}guez and N. Madrid},
  booktitle = {Proceedings of the 14th IADIS International Conference e-Learning 2020, EL 2020 - Part of the 14th Multi Conference on Computer Science and Information Systems, MCCSIS 2020},
  title = {Using formal concept analysis to explore hidden knowledge in the assessment of amath course},
  year = {2020},
  note = {cited By 0; Conference of 14th IADIS International Conference e-Learning 2020, EL 2020, Part of the 14th Multi Conference on Computer Science and Information Systems, MCCSIS 2020 ; Conference Date: 21 July 2020 Through 23 July 2020; Conference Code:166581},
  pages = {39-46},
  publisher = {IADIS},
  abstract = {Since the emergence of COVID-19, online teaching and e-Learning has become essential in education. Actually, in at our University, we have had to move to a complete online teaching framework through the Moodle e-learning system. As a result, we have had to deploy new material as videos in Youtube channels, newexercises, tasks, live teaching, etc that have generated a huge amount of data that contains interesting information. In particular, we have used randomly generated exams from a bank of quizzes to evaluate the students. In this paper, we analyze the results of these quizzes using Formal Concept Analysis tools in order to check the hidden knowledge in the assessment process with the goal of improving the developed material for next years. In addition, we will analyze how the different exercises and tests relate to each other so that we can use this information in the following courses to improve our lectures. © Proceedings of the 14th IADIS International Conference e-Learning 2020, EL 2020 - Part of the 14th Multi Conference on Computer Science and Information Systems, MCCSIS 2020. All rights reserved.},
  author_keywords = {Concepts; E-Learning Assessment Tools; Formal Concept Analysis; Knowledge Mining; Quizzes; Random Exams},
  document_type = {Conference Paper},
  keywords = {E-learning; Information analysis; Information systems; Information use; Learning systems; Teaching, Assessment process; Formal concepts; Hidden knowledge; Interesting information; Live teaching; Online teaching; YouTube, Formal concept analysis},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85101161899&partnerID=40&md5=91ad6b849d5459061df3c0143b72bf5c},
}

@InProceedings{Ojeda-Hernandez202162,
  author = {M. Ojeda-Hern{\a'a}ndez and F. P{\a'e}rez-G{\a'a}mez and {\a'A}. Mora-Bonilla and D. L{\a'o}pez-Rodr{\a'\i}guez},
  title = {Using logic to determine key items in math education},
  booktitle = {15th International Conference e-Learning, EL 2021 - Held at the 15th Multi-Conference on Computer Science and Information Systems, MCCSIS 2021},
  year = {2021},
  pages = {62-69},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85117688099&partnerID=40&md5=85bb65037a2dc1d70fbb879fe2b905e2},
  abstract = {Due to the COVID-19 restrictions, high-schools in Spain are having both online and in-class lectures. As a result, the students can use not only the information provided by the teachers in class, but they can also use several other methods such as videos and online examples that allow the students to have materials from different places. In this paper, we analyse the Mathematics results of the first two terms in a secondary school from Andalusia. This analysis can help find the central units of the subject found, that is, giving enough background knowledge to keep up with the module. When these are found, the teachers can improve the learning and the results in the following years. © 15th International Conference e-Learning, EL 2021 - Held at the 15th Multi-Conference on Computer Science and Information Systems, MCCSIS 2021. All rights reserved.},
  author_keywords = {E-Learning Assessment Tools;  Formal Concept Analysis;  Implications;  Knowledge Mining},
  keywords = {Data mining;  Formal concept analysis;  Information systems;  Information use;  Students, Assessment tool;  E - learning;  E-learning assessment tool;  Formal concepts analysis;  Higher School;  Implication;  In-class lectures;  Knowledge mining;  Learning assessment;  Teachers', E-learning},
  publisher = {IADIS},
  isbn = {9789898704290},
}

@InProceedings{Lopez-Rodriguez21,
  author = {Domingo L{\a'o}pez-Rodr{\a'\i}guez and Pablo Cordero and Manuel Enciso and Angel Mora},
  editor = {Agn{\a`e}s Braud and Aleksey Buzmakov and Tom Hanika and Florence Le Ber},
  title = {Clustering and Identification of Core Implications},
  booktitle = {Formal Concept Analysis - 16th International Conference, {ICFCA} 2021,
               Strasbourg, France, June 29 - July 2, 2021, Proceedings},
  series = {Lecture Notes in Computer Science},
  volume = {12733},
  pages = {138--154},
  publisher = {Springer},
  year = {2021},
  url = {https://doi.org/10.1007/978-3-030-77867-5\_9},
  doi = {10.1007/978-3-030-77867-5\_9},
  timestamp = {Tue, 13 Jul 2021 13:28:00 +0200},
  biburl = {https://dblp.org/rec/conf/icfca/Lopez-Rodriguez21.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
}

@InProceedings{maza2021rician,
  title = {Rician Noise Estimation for 3D Magnetic Resonance Images Based on Benford’s Law},
  author = {Rosa Maza-Quiroga and Karl Thurnhofer-Hemsi and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Ezequiel L{\a'o}pez-Rubio},
  booktitle = {International Conference on Medical Image Computing and Computer-Assisted Intervention},
  pages = {340--349},
  year = {2021},
  organization = {Springer},
}

@InProceedings{CLA2022Revisiting,
  title = {Revisiting Algorithms for Fuzzy Concept Lattices},
  author = {D. L{\a'o}pez-Rodr{\a'\i}guez and {\a'A}. Mora and M. Ojeda-Hern{\a'a}ndez},
  booktitle = {The 16th International Conference on Concept Lattices and Applications},
  pages = {107 -- 118},
  year = {2022},
  organization = {CLA},
}

@InProceedings{fcaRCLA,
  title = {fcaR, Spreading FCA to the Data Science World},
  author = {Pablo Cordero and Manuel Enciso and Domingo L{\a'o}pez-Rodr{\a'\i}guez and {\a'A}ngel Mora},
  booktitle = {Proceedings of the Sixteenth International Conference on Concept Lattices and Their Applications},
  pages = {201 -- 207},
  year = {2022},
  organization = {CLA},
}

@InProceedings{Mixed-IPMU,
  author = {Francisco P{\a'e}rez-G{\a'a}mez and Pablo Cordero and Manuel Enciso and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Angel Mora},
  editor = {Davide Ciucci and In{\a'e}s Couso and Jes{\a'u}s Medina and Dominik Slezak and Davide Petturiti and Bernadette Bouchon-Meunier and Ronald R. Yager},
  title = {Computing the Mixed Concept Lattice},
  booktitle = {Information Processing and Management of Uncertainty in Knowledge-Based
               Systems - 19th International Conference, {IPMU} 2022, Milan, Italy,
               July 11-15, 2022, Proceedings, Part {I}},
  series = {Communications in Computer and Information Science},
  volume = {1601},
  pages = {87--99},
  publisher = {Springer},
  year = {2022},
  url = {https://doi.org/10.1007/978-3-031-08971-8\_8},
  doi = {10.1007/978-3-031-08971-8\_8},
  timestamp = {Mon, 25 Jul 2022 08:39:18 +0200},
  biburl = {https://dblp.org/rec/conf/ipmu/Perez-GamezCEL022.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
}

@InProceedings{Clara2021,
  author = {Clara Jim{\a'e}nez-Valverde and Rosa Mar{\a'\i}a Maza-Quiroga and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Karl Thurnhofer-Hemsi and Ezequiel L{\a'o}pez-Rubio and Rafael Marcos Luque-Baena},
  editor = {Jos{\a'e} Manuel {Ferr{\a'a}ndez Vicente} and Jos{\a'e} Ram{\a'o}n {\a'A}lvarez-S{\a'a}nchez and F{\a'e}lix {de la Paz L{\a'o}pez} and Hojjat Adeli},
  title = {Analysis of Functional Connectome Pipelines for the Diagnosis of Autism Spectrum Disorders},
  booktitle = {Bio-inspired Systems and Applications: from Robotics to Ambient Intelligence},
  year = {2022},
  publisher = {Springer International Publishing},
  address = {Cham},
  pages = {213--222},
  abstract = {This paper explores the effect of using different pipelines to compute connectomes (matrices representing brain connections) and use them to train machine learning models with the goal of diagnosing Autism Spectrum Disorder. Five different pipelines are used to train six different ML models, splitting the data into female, male and all subsets so we can also research the effect of considering male and female patients separately. Our results conclude that pipeline and model choice impact results, along with using general or specific models.},
  isbn = {978-3-031-06527-9},
}

@InProceedings{ICCS2023,
  author = {Carlos Bejines and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Manuel Ojeda-Hern{\a'a}ndez},
  editor = {Manuel Ojeda-Aciego and Kai Sauerwald and Robert J{\"a}schke},
  title = {Aggregation Functions and Extent Structure Preservation in Formal
                  Concept Analysis},
  booktitle = {Graph-Based Representation and Reasoning - 28th International Conference
                  on Conceptual Structures, {ICCS} 2023, Berlin, Germany, September
                  11-13, 2023, Proceedings},
  series = {Lecture Notes in Computer Science},
  volume = {14133},
  pages = {28--35},
  publisher = {Springer},
  year = {2023},
  url = {https://doi.org/10.1007/978-3-031-40960-8\_3},
  doi = {10.1007/978-3-031-40960-8\_3},
}

@Article{criado2004,
  author = {D. L{\a'o}pez and C. Criado},
  title = {A Pedagogical Simulation of Maxwells Demon Paradox},
  journal = {Journal of Chemical Education},
  volume = {81},
  number = {11},
  pages = {1679},
  year = {2004},
  doi = {10.1021/ed081p1679.2},
  abstract = { This program simulates, at the microscopic level, two gas chambers with an opening between them. The program allows users to set up simulations that illustrate the thermodynamics and statistical behavior of the system. The user determines the basis for whether the demon permits or denies passage of particles through the opening using information from the microscopic level. },
}

@Article{galan2007improving,
  title = {Improving neural networks for mechanism kinematic chain isomorphism identification},
  author = {Gloria Galan-Marin and Enrique Merida-Casermeiro and Domingo Lopez-Rodriguez},
  journal = {Neural processing letters},
  volume = {26},
  number = {2},
  pages = {133--143},
  year = {2007},
  publisher = {Springer},
}

@Article{LopezRodriguez2007,
  author = {D. L{\a'o}pez-Rodr{\a'\i}guez and E. M{\a'e}rida-Casermeiro and J.M. Ortiz-de-Lazcano-Lobato},
  journal = {WSEAS Transactions on Mathematics},
  title = {Stochastic multivalued network for optimization. Application to the graph MaxCut problem},
  year = {2007},
  note = {cited By 0},
  number = {3},
  pages = {500-505},
  volume = {6},
  abstract = {The aim of this paper is to present the stochastic version of the multivalued neural model MREM, which has achieved very good results in many applications, as an optimization technique. The purpose of this stochastic version is to avoid certain local minima of the objective function minimized by the network, that is, the energy function. To this end, the description of the theoretical bases of this model, guaranteeing the convergence to minima, is carried out rigorously. In order to show the efficiency of this new model, the model, in its two versions, deterministic and stochastic, has been applied to the resolution of the well-known problem of graph partition, MaxCut. Computational experiments show that in most cases the stochastic model achieves better results than the deterministic one.},
  author_keywords = {Graph problems; Neural networks; Optimization problems; Stochastic dynamics},
  document_type = {Article},
  keywords = {Computational efficiency; Graph theory; Mathematical models; Optimization; Stochastic models, Graph partition; Local minima; Stochastic dynamics, Neural networks},
  source = {Scopus},
  url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-33847621572&partnerID=40&md5=be8fe4152a9d2279f0a282de53806edb},
}

@Article{Lopez-RubioOL09,
  author = {Ezequiel L{\a'o}pez-Rubio and Juan Miguel Ortiz-de-Lazcano-Lobato and Domingo L{\a'o}pez-Rodr{\a'\i}guez},
  title = {Probabilistic {PCA} Self-Organizing Maps},
  journal = {{IEEE} Trans. Neural Networks},
  volume = {20},
  number = {9},
  pages = {1474--1489},
  year = {2009},
  url = {https://doi.org/10.1109/TNN.2009.2025888},
  doi = {10.1109/TNN.2009.2025888},
  timestamp = {Wed, 14 Nov 2018 10:32:52 +0100},
  biburl = {https://dblp.org/rec/journals/tnn/Lopez-RubioOL09.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
}

@Article{MarinLC10,
  author = {Gloria Gal{\a'a}n Mar{\a'\i}n and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Enrique M{\a'e}rida Casermeiro},
  title = {A New Multivalued Neural Network for Isomorphism Identification of
               Kinematic Chains},
  journal = {J. Comput. Inf. Sci. Eng.},
  volume = {10},
  number = {1},
  year = {2010},
  url = {https://doi.org/10.1115/1.3330427},
  doi = {10.1115/1.3330427},
  timestamp = {Thu, 21 Jan 2021 17:35:20 +0100},
  biburl = {https://dblp.org/rec/journals/jcise/MarinLC10.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
}

@Article{perez2018energy,
  title = {Energy-aware acceleration on GPUs: findings on a bioinformatics benchmark},
  author = {Jes{\a'u}s P{\a'e}rez and Andr{\a'e}s Rodr{\a'\i}guez and Juan Francisco Chico and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Manuel Ujald{\a'o}n},
  journal = {Sustainable Computing: Informatics and Systems},
  volume = {20},
  pages = {88--101},
  year = {2018},
  publisher = {Elsevier},
  doi = {10.1016/j.suscom.2018.01.001},
}

@Article{cordero2020,
  title = {A conversational recommender system for diagnosis using fuzzy rules},
  author = {Pablo Cordero and Manuel Enciso and D L{\a'o}pez and Angel Mora},
  journal = {Expert Systems with Applications},
  volume = {154},
  pages = {113449},
  year = {2020},
  publisher = {Elsevier},
}

@Article{MinGen-IJCIS,
  author = {Manuel Ojeda-Hern{\a'a}ndez and Francisco P{\a'e}rez-G{\a'a}mez and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Nicol{\a'a}s Madrid and Angel Mora},
  title = {Minimal Generators from Positive and Negative Attributes: Analysing
               the Knowledge Space of a Mathematics Course},
  journal = {Int. J. Comput. Intell. Syst.},
  volume = {15},
  number = {1},
  pages = {58},
  year = {2022},
  url = {https://doi.org/10.1007/s44196-022-00123-3},
  doi = {10.1007/s44196-022-00123-3},
  timestamp = {Mon, 15 Aug 2022 15:04:55 +0200},
  biburl = {https://dblp.org/rec/journals/ijcisys/Ojeda-Hernandez22.bib},
  bibsource = {dblp computer science bibliography, https://dblp.org},
}

@Article{math10040607,
  author = {Francisco P{\a'e}rez-G{\a'a}mez and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Pablo Cordero and {\a'A}ngel Mora and Manuel Ojeda-Aciego},
  title = {Simplifying Implications with Positive and Negative Attributes: A Logic-Based Approach},
  journal = {Mathematics},
  volume = {10},
  year = {2022},
  number = {4},
  article-number = {607},
  url = {https://www.mdpi.com/2227-7390/10/4/607},
  issn = {2227-7390},
  abstract = {Concepts and implications are two facets of the knowledge contained within a binary relation between objects and attributes. Simplification logic (SL) has proved to be valuable for the study of attribute implications in a concept lattice, a topic of interest in the more general framework of formal concept analysis (FCA). Specifically, SL has become the kernel of automated methods to remove redundancy or obtain different types of bases of implications. Although originally FCA used only the positive information contained in the dataset, negative information (explicitly stating that an attribute does not hold) has been proposed by several authors, but without an adequate set of equivalence-preserving rules for simplification. In this work, we propose a mixed simplification logic and a method to automatically remove redundancy in implications, which will serve as a foundational standpoint for the automated reasoning methods for this extended framework.},
  doi = {10.3390/math10040607},
}

@Article{RJ-2022-014,
  author = {Pablo Cordero and Manuel Enciso and Domingo L{\a'o}pez-Rodr{\a'\i}guez and {\a'A}ngel Mora},
  title = {fcaR, Formal Concept Analysis with R},
  journal = {The R Journal},
  year = {2022},
  note = {https://doi.org/10.32614/RJ-2022-014},
  doi = {10.32614/RJ-2022-014},
  volume = {14},
  issue = {1},
  issn = {2073-4859},
  pages = {341-361},
}

@Article{ufug2022,
  title = {Detection of unfavourable urban areas with higher temperatures and lack of green spaces using satellite imagery in sixteen Spanish cities},
  journal = {Urban Forestry \& Urban Greening},
  volume = {78},
  pages = {127783},
  year = {2022},
  issn = {1618-8667},
  doi = {https://doi.org/10.1016/j.ufug.2022.127783},
  url = {https://www.sciencedirect.com/science/article/pii/S1618866722003260},
  author = {Francisco Rodr{\a'\i}guez-G{\a'o}mez and Rafael Fern{\a'a}ndez-Ca{\~n}ero and Gabriel P{\a'e}rez and Jos{\a'e} {del Campo-{\a'A}vila} and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Luis P{\a'e}rez-Urrestarazu},
  keywords = {Urban greening, Remote sensing, Heat island, Normalized difference vegetation index, Landsat-8},
}

@Article{axioms12040324,
  author = {Manuel Ojeda-Hern{\a'a}ndez and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Pablo Cordero},
  title = {Fuzzy Algebras of Concepts},
  journal = {Axioms},
  volume = {12},
  year = {2023},
  number = {4},
  article-number = {324},
  url = {https://www.mdpi.com/2075-1680/12/4/324},
  issn = {2075-1680},
  abstract = {Preconcepts are basic units of knowledge that form the basis of formal concepts in formal concept analysis (FCA). This paper investigates the relations among different kinds of preconcepts, such as protoconcepts, meet and join-semiconcepts and formal concepts. The first contribution of this paper, is to present a fuzzy powerset lattice gradation, that coincides with the preconcept lattice at its 1-cut. The second and more significant contribution, is to introduce a preconcept algebra gradation that yields different algebras for protoconcepts, semiconcepts, and concepts at different cuts. This result reveals new insights into the structure and properties of the different categories of preconcepts.},
  doi = {10.3390/axioms12040324},
}

@Article{axioms12121117,
  author = {Rosa Maza-Quiroga and Karl Thurnhofer-Hemsi and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Ezequiel L{\a'o}pez-Rubio},
  title = {Regression of the Rician Noise Level in 3D Magnetic Resonance Images from the Distribution of the First Significant Digit},
  journal = {Axioms},
  volume = {12},
  year = {2023},
  number = {12},
  article-number = {1117},
  url = {https://www.mdpi.com/2075-1680/12/12/1117},
  issn = {2075-1680},
  abstract = {This paper investigates the distribution characteristics of Fourier, discrete cosine, and discrete sine transform coefficients in T1 MRI images. This paper reveals their adherence to Benford&rsquo;s law, characterized by a logarithmic distribution of first digits. The impact of Rician noise on the first digit distribution is examined, which causes deviations from the ideal distribution. A novel methodology is proposed for noise level estimation, employing metrics such as the Bhattacharyya distance, Kullback&ndash;Leibler divergence, total variation distance, Hellinger distance, and Jensen&ndash;Shannon divergence. Supervised learning techniques utilize these metrics as regressors. Evaluations on MRI scans from several datasets coming from a wide range of different acquisition devices of 1.5 T and 3 T, comprising hundreds of patients, validate the adherence of noiseless T1 MRI frequency domain coefficients to Benford&rsquo;s law. Through rigorous experimentation, our methodology has demonstrated competitiveness with established noise estimation techniques, even surpassing them in numerous conducted experiments. This research empirically supports the application of Benford&rsquo;s law in transforms, offering a reliable approach for noise estimation in denoising algorithms and advancing image quality assessment.},
  doi = {10.3390/axioms12121117},
}

@Article{ijar2023,
  title = {Lexicon-based sentiment analysis in texts using Formal Concept Analysis},
  journal = {International Journal of Approximate Reasoning},
  volume = {155},
  pages = {104-112},
  year = {2023},
  issn = {0888-613X},
  doi = {https://doi.org/10.1016/j.ijar.2023.02.001},
  url = {https://www.sciencedirect.com/science/article/pii/S0888613X23000130},
  author = {Manuel Ojeda-Hern{\a'a}ndez and Domingo L{\a'o}pez-Rodr{\a'\i}guez and {\a'A}ngel Mora},
  keywords = {Formal Concept Analysis, Sentiment analysis, Polarity analysis, Text mining, Lexicon},
}

@Article{insci2023,
  title = {Connecting concept lattices with bonds induced by external information},
  author = {Ondrej Kr{\a'\i}dlo and Domingo L{\a'o}pez-Rodr{\a'\i}guez and Lubomir Antoni and Peter Elia{\v s} and Stanislav Kraj{\v c}i and Manuel Ojeda-Aciego},
  journal = {Information Sciences},
  pages = {119498},
  year = {2023},
  publisher = {Elsevier},
}
