---
author: Enrique Mérida Casermeiro, Domingo López-Rodríguez, Gloria Galán Marín, Juan
  Miguel Ortiz-de-Lazcano-Lobato
Status: Published
date: '2007-01-01'
slug: 2007-icannga2
title: Improved Production of Competitive Learning Rules with an Additional Term for
  Vector Quantization
categories:
- Competitive learning
- Neural networks
- Image processing
header_image: ~
details: Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial
  Intelligence and Lecture Notes in Bioinformatics), (4431), PART 1, <em>pp. 461&ndash;469</em>
doi: 10.1007/978-3-540-71618-1_51
link: 2007-icannga2/paper.pdf
project: ''
abstract: In this work, a general framework for developing learning rules with an
  added term (perturbation term) is presented. Many learning rules commonly cited
  in the specialized literature can be derived from this general framework. This framework
  allows us to introduce some knowledge about vector quantization (as an optimization
  problem) in the distortion function in order to derive a new learning rule that
  uses that information to avoid certain local minima of the distortion function,
  leading to better performance than classical models. Computational experiments in
  image compression show that our proposed rule, derived from this general framework,
  can achieve better results than simple competitive learning and other models, with
  codebooks of less distortion. © Springer-Verlag Berlin Heidelberg 2007.
howtocite: |
  `r library(RefManageR); s <- ReadBib('cite.bib'); NoCite(s);  capture.output(PrintBibliography(s, .opts = list(bib.style = 'alphabetic', style = 'markdown')))`
bibtex: |
  `r source('../../../format_bibtex.R');format_bibtex('cite.bib')`
keywords: Mathematical models, Perturbation techniques, Vector quantization, Competitive
  learning, Distortion function, Learning rules, Specialized literature, Learning
  systems
---
# Abstract

In this work, a general framework for developing learning rules with an added term (perturbation term) is presented. Many learning rules commonly cited in the specialized literature can be derived from this general framework. This framework allows us to introduce some knowledge about vector quantization (as an optimization problem) in the distortion function in order to derive a new learning rule that uses that information to avoid certain local minima of the distortion function, leading to better performance than classical models. Computational experiments in image compression show that our proposed rule, derived from this general framework, can achieve better results than simple competitive learning and other models, with codebooks of less distortion. © Springer-Verlag Berlin Heidelberg 2007.

```{r citing}
#| echo: false
#| results: asis
#| warning: false
#| message: false

if (file.exists("citation_history.rds")) {
  
  cat("# Cites\n")
  cat("The following graph plots the number of cites received by this work from its publication, on a yearly basis.\n")
  
}
```

```{r citing2}
#| echo: false
#| results: asis
#| warning: false
#| message: false

if (file.exists("citation_history.rds")) {
  
  source(here::here("scripts", "manage_publications.R"))
  df <- readRDS("citation_history.rds")
  plot_citation_history(df)
  
}
```


# Citation

Please, cite this work as:

```{r citation1, results='asis', echo = FALSE}
this_folder <- here::here('publications', 'conferences', '2007-icannga2')
library(RefManageR)
s <- ReadBib(file.path(this_folder, 'cite.bib'))
NoCite(s) 
options(width = 1000) 
txt <- capture.output(PrintBibliography(s, .opts = list(bib.style = 'alphabetic', style = 'markdown')))
cat(txt)
```

  

::: {.callout-note appearance="minimal" collapse=true}

## BibTeX
<!-- If you, like me, use $\LaTeX$, the following BibTeX entry will be helpful: -->
  
```{r citation2, warning=FALSE,  results='asis', echo = FALSE}
source(here::here('format_bibtex.R'))
cat(format_bibtex(file.path(this_folder, 'cite.bib')))
```

:::
