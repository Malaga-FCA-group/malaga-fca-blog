---
author: E. López-Rubio, J.M. Ortiz-de-Lazcano-Lobato, Domingo López-Rodríguez, E.
  Mérida-Casermeiro, M.D.C. Vargas-González
Status: Published
date: '2006-01-01'
slug: 2006-asc
title: Global-local learning strategies in probabilistic principal components analysis
categories:
- Neural networks
- Competitive learning
- Principal component analysis
header_image: ~
details: Proceedings of the 10th IASTED International Conference on Artificial Intelligence
  and Soft Computing, ASC 2006, <em>pp. 46-51</em>
doi: ''
link: 2006-asc/paper.pdf
project: ''
abstract: We present a neural model which extends classical competitive learning by
  performing a Probabilistic Principal Components Analysis at each neuron. In the
  learning process is utilized a competition rule which try to get the better representation
  of the dataset while maintaining the homogeneity of the formed clusters. The model
  also has the ability to learn the number of basis vectors required to represent
  the principal directions of each cluster, so it overcomes a drawback of most local
  PCA models, where the dimensionality of a cluster must be fixed a priori.
howtocite: |
  `r library(RefManageR); s <- ReadBib('cite.bib'); NoCite(s);  capture.output(PrintBibliography(s, .opts = list(bib.style = 'alphabetic', style = 'markdown')))`
bibtex: |
  `r source('../../../format_bibtex.R');format_bibtex('cite.bib')`
keywords: Artificial intelligence, Education, Neural networks, Probability, Soft computing,
  Basis vectors, Competition rules, Competitive learning, Competitive learnings, Learning
  processes, Local learning strategies, Local PCA, Neural models, Pca models, Principal
  components analyses, Principal directions, Principal component analysis
---
# Abstract

We present a neural model which extends classical competitive learning by performing a Probabilistic Principal Components Analysis at each neuron. In the learning process is utilized a competition rule which try to get the better representation of the dataset while maintaining the homogeneity of the formed clusters. The model also has the ability to learn the number of basis vectors required to represent the principal directions of each cluster, so it overcomes a drawback of most local PCA models, where the dimensionality of a cluster must be fixed a priori.

```{r citing}
#| echo: false
#| results: asis
#| warning: false
#| message: false

if (file.exists("citation_history.rds")) {
  
  cat("# Cites\n")
  cat("The following graph plots the number of cites received by this work from its publication, on a yearly basis.\n")
  
}
```

```{r citing2}
#| echo: false
#| results: asis
#| warning: false
#| message: false

if (file.exists("citation_history.rds")) {
  
  source(here::here("scripts", "manage_publications.R"))
  df <- readRDS("citation_history.rds")
  plot_citation_history(df)
  
}
```


# Citation

Please, cite this work as:

```{r citation1, results='asis', echo = FALSE}
this_folder <- here::here('publications', 'conferences', '2006-asc')
library(RefManageR)
s <- ReadBib(file.path(this_folder, 'cite.bib'))
NoCite(s) 
options(width = 1000) 
txt <- capture.output(PrintBibliography(s, .opts = list(bib.style = 'alphabetic', style = 'markdown')))
cat(txt)
```

  

::: {.callout-note appearance="minimal" collapse=true}

## BibTeX
<!-- If you, like me, use $\LaTeX$, the following BibTeX entry will be helpful: -->
  
```{r citation2, warning=FALSE,  results='asis', echo = FALSE}
source(here::here('format_bibtex.R'))
cat(format_bibtex(file.path(this_folder, 'cite.bib')))
```

:::
