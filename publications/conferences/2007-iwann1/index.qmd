---
author: E. López-Rubio, J.M. Ortiz-De-Lazcano-Lobato, Domingo López-Rodríguez, M.
  Del Carmen Vargas-González
Status: Published
date: '2007-01-01'
slug: 2007-iwann1
title: Automatic Model Selection for Probabilistic {PCA}
categories:
- Principal component analysis
- Neural networks
header_image: ~
details: Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial
  Intelligence and Lecture Notes in Bioinformatics), (4507 LNCS), <em>pp. 127-134</em>
doi: 10.1007/978-3-540-73007-1_16
link: 2007-iwann1/paper.pdf
project: ''
keywords: Approximation theory, Bayesian networks, Gaussian distribution, Mathematical
  models, Probability density function, Multivariate analysis, Optimal model selection,
  Principal component analysis
---



# Abstract


The Mixture of Probabilistic Principal Components Analyzers (MPPCA) is a multivariate analysis technique which defines a Gaussian probabilistic model at each unit. The number of units and principal directions in each unit is not learned in the original approach. Variational Bayesian approaches have been proposed for this purpose, which rely on assumptions on the input distribution and/or approximations of certain statistics. Here we present a different way to solve this problem, where cross-validation is used to guide the search for an optimal model selection. This allows to learn the model architecture without the need of any assumptions other than those of the basic PPCA framework. Experimental results are presented, which show the probability density estimation capabilities of the proposal with high dimensional data. © Springer-Verlag Berlin Heidelberg 2007.





# Cites

The following graph plots the number of cites received by this work from its publication, on a yearly basis.

```{r citing2}
#| echo: false
#| results: asis
#| warning: false
#| message: false
source(here::here('scripts', 'manage_publications.R'))
df <- readRDS('citation_history.rds')
plot_citation_history(df)
```


# Citation
Please, cite this work as:


<a name=bib-LopezRubio2007b></a>[[Lóp+07]](#cite-LopezRubio2007b) E. López-Rubio, J. Ortiz-De-Lazcano-Lobato, D. López-Rodríguez, et al. “Automatic Model Selection for Probabilistic PCA”. In: _Computational and Ambient Intelligence, 9th International Work-Conference on Artificial Neural Networks, IWANN 2007, San Sebastián, Spain, June 20-22, 2007, Proceedings_. Ed. by F. S. Hernández, A. Prieto, J. Cabestany and M. Gra~na. Vol. 4507 LNCS. Lecture Notes in Computer Science. cited By 0; Conference of 9th International Work-Conference on Artificial Neural Networks, IWANN 2007 ; Conference Date: 20 June 2007 Through 22 June 2007; Conference Code:71094. San Sebastian: Springer Verlag, 2007, pp. 127-134. DOI: [10.1007/978-3-540-73007-1_16](https://doi.org/10.1007%2F978-3-540-73007-1_16). URL: [https://doi.org/10.1007/978-3-540-73007-1_16](https://doi.org/10.1007/978-3-540-73007-1_16).

::: {.callout-note appearance="minimal" collapse=true}

## BibTeX

@InProceedings{LopezRubio2007b,<br>&nbsp;&nbsp;&nbsp;&nbsp;  author = {E. López-Rubio and J.M. Ortiz-De-Lazcano-Lobato and D. López-Rodríguez and M. {Del Carmen Vargas-González}},<br>&nbsp;&nbsp;&nbsp;&nbsp;  booktitle = {Computational and Ambient Intelligence, 9th International Work-Conference on Artificial Neural Networks, {IWANN} 2007, San Sebastián, Spain, June 20-22, 2007, Proceedings},<br>&nbsp;&nbsp;&nbsp;&nbsp;  title = {Automatic Model Selection for Probabilistic {PCA}},<br>&nbsp;&nbsp;&nbsp;&nbsp;  year = {2007},<br>&nbsp;&nbsp;&nbsp;&nbsp;  address = {San Sebastian},<br>&nbsp;&nbsp;&nbsp;&nbsp;  editor = {Francisco Sandoval Hernández and Alberto Prieto and Joan Cabestany and Manuel Gra{\~n}a},<br>&nbsp;&nbsp;&nbsp;&nbsp;  note = {cited By 0; Conference of 9th International Work-Conference on Artificial Neural Networks, IWANN 2007 ; Conference Date: 20 June 2007 Through 22 June 2007; Conference Code:71094},<br>&nbsp;&nbsp;&nbsp;&nbsp;  pages = {127-134},<br>&nbsp;&nbsp;&nbsp;&nbsp;  publisher = {Springer Verlag},<br>&nbsp;&nbsp;&nbsp;&nbsp;  series = {Lecture Notes in Computer Science},<br>&nbsp;&nbsp;&nbsp;&nbsp;  volume = {4507 LNCS},<br>&nbsp;&nbsp;&nbsp;&nbsp;  abstract = {The Mixture of Probabilistic Principal Components Analyzers (MPPCA) is a multivariate analysis technique which defines a Gaussian probabilistic model at each unit. The number of units and principal directions in each unit is not learned in the original approach. Variational Bayesian approaches have been proposed for this purpose, which rely on assumptions on the input distribution and/or approximations of certain statistics. Here we present a different way to solve this problem, where cross-validation is used to guide the search for an optimal model selection. This allows to learn the model architecture without the need of any assumptions other than those of the basic PPCA framework. Experimental results are presented, which show the probability density estimation capabilities of the proposal with high dimensional data. © Springer-Verlag Berlin Heidelberg 2007.},<br>&nbsp;&nbsp;&nbsp;&nbsp;  author_keywords = {Cross-validation; Dimensionality reduction; Handwritten digit recognition; Probabilistic Principal Components Analysis (PPCA)},<br>&nbsp;&nbsp;&nbsp;&nbsp;  bibsource = {dblp computer science bibliography, https://dblp.org},<br>&nbsp;&nbsp;&nbsp;&nbsp;  biburl = {https://dblp.org/rec/conf/iwann/Lopez-RubioOLV07.bib},<br>&nbsp;&nbsp;&nbsp;&nbsp;  document_type = {Conference Paper},<br>&nbsp;&nbsp;&nbsp;&nbsp;  doi = {10.1007/978-3-540-73007-1_16},<br>&nbsp;&nbsp;&nbsp;&nbsp;  journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},<br>&nbsp;&nbsp;&nbsp;&nbsp;  keywords = {Approximation theory; Bayesian networks; Gaussian distribution; Mathematical models; Probability density function, Multivariate analysis; Optimal model selection, Principal component analysis},<br>&nbsp;&nbsp;&nbsp;&nbsp;  source = {Scopus},<br>&nbsp;&nbsp;&nbsp;&nbsp;  url = {https://doi.org/10.1007/978-3-540-73007-1_16},<br>}

:::


